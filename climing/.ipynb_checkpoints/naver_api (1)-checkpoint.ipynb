{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5022b232",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색할 값을 입력해 주세요. :등산로\n",
      "{\n",
      "\t\"lastBuildDate\":\"Mon, 08 Apr 2024 16:54:27 +0900\",\n",
      "\t\"total\":1070490,\n",
      "\t\"start\":1,\n",
      "\t\"display\":10,\n",
      "\t\"items\":[\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"아차산 주차장(아차산역 및 고구려대장간마을) 5곳, <b>등산로<\\/b> 입구\",\n",
      "\t\t\t\"link\":\"https:\\/\\/blog.naver.com\\/bonokebi1202\\/223396146893\",\n",
      "\t\t\t\"description\":\"차량 가지고 아차산 등산하실 때 알아두면 좋은 아차산 주차장 5곳 그리고 <b>등산로<\\/b> 입구 정리해 볼까... 사찰 옆에 <b>등산로<\\/b> 입구가 있습니다. 기원정사 사찰 외에도 <b>등산로<\\/b> 입구가 또 있는데요. 바로 여기!!!... \",\n",
      "\t\t\t\"bloggername\":\"산타는 고은이\",\n",
      "\t\t\t\"bloggerlink\":\"blog.naver.com\\/bonokebi1202\",\n",
      "\t\t\t\"postdate\":\"20240326\"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"쉽다던 아차산 <b>등산로<\\/b>, 광나루역에서 사가정역까지\",\n",
      "\t\t\t\"link\":\"https:\\/\\/blog.naver.com\\/dmlgml76\\/223251154754\",\n",
      "\t\t\t\"description\":\"아차산<b>등산로<\\/b> 입구 만남의 광장이다. 우측에 이동식 화장실 있어서 미리 해결. 생각보다 깨끗해서... <b>등산로<\\/b> 같기도 공원같기도 한... 보루같은 유적지들이 있어서 그런것 같기도 하고. 여기가 정상~ 아니고요~ 탁... \",\n",
      "\t\t\t\"bloggername\":\"1% 다르게...\",\n",
      "\t\t\t\"bloggerlink\":\"blog.naver.com\\/dmlgml76\",\n",
      "\t\t\t\"postdate\":\"20231031\"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"동계라 막혀있던 홍천 팔봉산 관광지 <b>등산로<\\/b> 캠핑장 유원지 모습\",\n",
      "\t\t\t\"link\":\"https:\\/\\/blog.naver.com\\/21140427\\/223346883891\",\n",
      "\t\t\t\"description\":\"동계 <b>등산로<\\/b> 전면 통제 기간 공유 팔봉산유원지  막혀있어 한적했던 홍천 캠핑장 모습 사진*글\\/바리형... 캠핑장부터 <b>등산로<\\/b>까지 통제상태라 공유 차 포스팅해요. 홍천 팔봉산관광지  주 소 : 강원 홍천군... \",\n",
      "\t\t\t\"bloggername\":\"바리형 믿고 따라와 ✈️\",\n",
      "\t\t\t\"bloggerlink\":\"blog.naver.com\\/21140427\",\n",
      "\t\t\t\"postdate\":\"20240207\"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"창녕 화왕산 등산 가을억새로 유명한 화왕산 자하곡1<b>등산로<\\/b>... \",\n",
      "\t\t\t\"link\":\"https:\\/\\/blog.naver.com\\/qor9474\\/223267693696\",\n",
      "\t\t\t\"description\":\"(토) 장소 : 창녕 화왕산 날씨 : 코스 : 자하곡매표소주차장-자하곡1<b>등산로<\\/b>-생명의숲-자하정-배바위-화왕산정상-자하곡3<b>등산로<\\/b>-도성암-자하곡매표소주차장(원점회귀) 거리 : 8.08㎞ 시간 : 4시간 41분(쉬엄쉬엄)... \",\n",
      "\t\t\t\"bloggername\":\"바람의 소리\",\n",
      "\t\t\t\"bloggerlink\":\"blog.naver.com\\/qor9474\",\n",
      "\t\t\t\"postdate\":\"20231117\"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"강화도 마니산 등산코스 함허동천 참성대 최단 <b>등산로<\\/b>\",\n",
      "\t\t\t\"link\":\"https:\\/\\/blog.naver.com\\/chs153chs\\/223398086295\",\n",
      "\t\t\t\"description\":\"인천 강화도 마니산의 최단 등산코스는 아니지만 함허동천 <b>등산로<\\/b>로 참성대까지 후기 아직도... 강화도 마니산 최단 등산코스 중 함허동천 <b>등산로<\\/b>와 참성대까지 포스팅을 정리해 보았습니다. 요 약 역사를... \",\n",
      "\t\t\t\"bloggername\":\"걷는러너 여행과 등산 트레일 러닝\",\n",
      "\t\t\t\"bloggerlink\":\"blog.naver.com\\/chs153chs\",\n",
      "\t\t\t\"postdate\":\"20240328\"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"군포시 수리산  산림욕장 황톳길 중앙 도서관 방면 <b>등산로<\\/b>를... \",\n",
      "\t\t\t\"link\":\"https:\\/\\/blog.naver.com\\/rndsoehd112\\/223406304080\",\n",
      "\t\t\t\"description\":\"군포시 수리산에 위치한 수리산 산림욕장 황톳길을 중앙 도서관 방면에서 시작하는 <b>등산로<\\/b> 코스에서... 군포시 중앙 도서관 방면에서 시작하는 수리산 <b>등산로<\\/b> 코스는 대중교통으로는 1호선의 경우에는 금정역... \",\n",
      "\t\t\t\"bloggername\":\"인생이 즐겁다.\",\n",
      "\t\t\t\"bloggerlink\":\"blog.naver.com\\/rndsoehd112\",\n",
      "\t\t\t\"postdate\":\"20240405\"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"서울근교 원적산 등산코스 영원사 들머리 주차 <b>등산로<\\/b>... \",\n",
      "\t\t\t\"link\":\"https:\\/\\/blog.naver.com\\/rokag4\\/223387920566\",\n",
      "\t\t\t\"description\":\"열리고 <b>등산로<\\/b>도 쉽다는 말이 있어 동생과 함게 찾아갔다. 하지만!!! 영원사 들머리로 하는 원적산... 원적산 등산코스 <b>등산로<\\/b> 상세 요약 ( 2024년 03월 16일 봄 산행 기준) 정개산, 원적산 <b>등산로<\\/b> 안내 영원사... \",\n",
      "\t\t\t\"bloggername\":\"팔도정복 하러 온 잠비\",\n",
      "\t\t\t\"bloggerlink\":\"blog.naver.com\\/rokag4\",\n",
      "\t\t\t\"postdate\":\"20240319\"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"[섬 그리고 산] 진도 접도 웰빙<b>등산로<\\/b> 봄맞이 트레킹!\",\n",
      "\t\t\t\"link\":\"https:\\/\\/blog.naver.com\\/khd4312\\/223379581876\",\n",
      "\t\t\t\"description\":\"10 산행코스: 여미주차장 ~ 접도 웰빙<b>등산로<\\/b>입구 ~ 남망산(쥐바위) ~ 병풍바위 ~ 선달봉 ~ 선달봉삼거리... 접도웰빙<b>등산로<\\/b> 섬이지만 육지와 다리로 연결된 진도에서 다시 다리로 연결된 접도까지 섬이지만 이제는... \",\n",
      "\t\t\t\"bloggername\":\"배가본드 내 인생\",\n",
      "\t\t\t\"bloggerlink\":\"blog.naver.com\\/khd4312\",\n",
      "\t\t\t\"postdate\":\"20240311\"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"등린이 일지.2 | 파주 파평산 산림공원 <b>등산로<\\/b> 정보\",\n",
      "\t\t\t\"link\":\"https:\\/\\/blog.naver.com\\/khannieandblues\\/223350515082\",\n",
      "\t\t\t\"description\":\"등린이 탈출기 스따뜨 경기도 파주시 파평면에 위치한 파평산 총평: 만만치 않았던 아직은 겨울이구나 초입에 산도령을(?) 만나면 맞게 가고있슴 한서방이 찾아준 파평산 <b>등산로<\\/b> 고고싱 지도에는 <b>등산로<\\/b>1,2,3,4가... \",\n",
      "\t\t\t\"bloggername\":\"~\",\n",
      "\t\t\t\"bloggerlink\":\"blog.naver.com\\/khannieandblues\",\n",
      "\t\t\t\"postdate\":\"20240211\"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"부산 기장 석은덤 병산숲길 <b>등산로<\\/b> 산행 후기\",\n",
      "\t\t\t\"link\":\"https:\\/\\/blog.naver.com\\/unilove012\\/223308164071\",\n",
      "\t\t\t\"description\":\"길이 험하고 헷갈린다고 해서 갈까 말까 고민하다가 최근에 <b>등산로<\\/b>를 정비했다는 글을 보고 다녀왔다.... 석은덤 <b>등산로<\\/b>는 해운대컨트리클럽 표지판 옆에 있다. 차 타고 올라가는 경우 주차도 여기에 하면 됨.... \",\n",
      "\t\t\t\"bloggername\":\"심주부 여행일기\",\n",
      "\t\t\t\"bloggerlink\":\"blog.naver.com\\/unilove012\",\n",
      "\t\t\t\"postdate\":\"20231231\"\n",
      "\t\t}\n",
      "\t]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "scroll_data = input('검색할 값을 입력해 주세요. :')\n",
    "client_id = \"ShIovNz7SXGAFNygBoVx\"\n",
    "client_secret = \"1Gh1DzPsn3\"\n",
    "encText = urllib.parse.quote(scroll_data)\n",
    "url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText # JSON 결과\n",
    "# url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # XML 결과\n",
    "request = urllib.request.Request(url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    print(response_body.decode('utf-8'))\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)\n",
    "\n",
    "log = response_body.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa721f2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색할 키워드를 입력해주세요:등산로\n",
      "\n",
      "크롤링을 끝낼 위치를 입력해주세요. (기본값:1, 최대값:100):\n",
      "\n",
      " 1 ~  1 페이지 까지 크롤링을 진행 합니다\n",
      "\n",
      "한번에 가져올 페이지 개수를 입력해주세요.(기본값:10, 최대값: 100):\n",
      "\n",
      "한번에 가져올 페이지 :  10 페이지\n",
      "https://blog.naver.com/bonokebi1202/223396146893\n",
      "https://blog.naver.com/dmlgml76/223251154754\n",
      "https://blog.naver.com/21140427/223346883891\n",
      "https://blog.naver.com/qor9474/223267693696\n",
      "https://blog.naver.com/chs153chs/223398086295\n",
      "https://blog.naver.com/rndsoehd112/223406304080\n",
      "https://blog.naver.com/rokag4/223387920566\n",
      "https://blog.naver.com/khd4312/223379581876\n",
      "https://blog.naver.com/khannieandblues/223350515082\n",
      "https://blog.naver.com/unilove012/223308164071\n",
      "https://blog.naver.com/sexysharon/223258673069\n",
      "아차산 주차장(아차산역 및 고구려대장간마을) 5곳, 등산로 입구\n",
      "쉽다던 아차산 등산로, 광나루역에서 사가정역까지\n",
      "동계라 막혀있던 홍천 팔봉산 관광지 등산로 캠핑장 유원지 모습\n",
      "창녕 화왕산 등산 가을억새로 유명한 화왕산 자하곡1등산로... \n",
      "강화도 마니산 등산코스 함허동천 참성대 최단 등산로\n",
      "군포시 수리산  산림욕장 황톳길 중앙 도서관 방면 등산로를... \n",
      "서울근교 원적산 등산코스 영원사 들머리 주차 등산로... \n",
      "[섬 그리고 산] 진도 접도 웰빙등산로 봄맞이 트레킹!\n",
      "등린이 일지.2 | 파주 파평산 산림공원 등산로 정보\n",
      "부산 기장 석은덤 병산숲길 등산로 산행 후기\n",
      "경기도 용인 석성산 단풍 등산로 등산코스 지도\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "\n",
    "# 웹드라이버 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "# 버전에 상관 없이 os에 설치된 크롬 브라우저 사용\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(3)\n",
    "# 버전에 상관 없이 os에 설치된 크롬 브라우저 사용\n",
    "\n",
    "\n",
    "# Naver API key 입력\n",
    "client_id = \"ShIovNz7SXGAFNygBoVx\"\n",
    "client_secret = \"1Gh1DzPsn3\"\n",
    "\n",
    "\n",
    "# selenium으로 검색 페이지 불러오기 #\n",
    "naver_urls = []\n",
    "postdate = []\n",
    "titles = []\n",
    "\n",
    "# 검색어 입력\n",
    "keword = input(\"검색할 키워드를 입력해주세요:\")\n",
    "encText = urllib.parse.quote(keword)\n",
    "\n",
    "# 검색을 끝낼 페이지 입력\n",
    "end = input(\"\\n크롤링을 끝낼 위치를 입력해주세요. (기본값:1, 최대값:100):\")  \n",
    "if end == \"\":\n",
    "    end = 1\n",
    "else:\n",
    "    end = int(end)\n",
    "print(\"\\n 1 ~ \", end, \"페이지 까지 크롤링을 진행 합니다\")\n",
    "\n",
    "# 한번에 가져올 페이지 입력\n",
    "display = input(\"\\n한번에 가져올 페이지 개수를 입력해주세요.(기본값:10, 최대값: 100):\")\n",
    "if display == \"\":\n",
    "    display = 10\n",
    "else:\n",
    "    display = int(display)\n",
    "print(\"\\n한번에 가져올 페이지 : \", display, \"페이지\")\n",
    "\n",
    "\n",
    "for start in range(end):\n",
    "    url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText + \"&start=\" + str(start+1) + \"&display=\" + str(display+1) # JSON 결과\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        \n",
    "        data = json.loads(response_body.decode('utf-8'))['items']\n",
    "        for row in data:\n",
    "            if('blog.naver' in row['link']):\n",
    "                naver_urls.append(row['link'])\n",
    "                postdate.append(row['postdate'])\n",
    "                title = row['title']\n",
    "                # html태그제거\n",
    "                pattern1 = '<[^>]*>'\n",
    "                title = re.sub(pattern=pattern1, repl='', string=title)\n",
    "                titles.append(title)\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "\n",
    "\n",
    "for i in naver_urls:\n",
    "    print(i)\n",
    "for i in titles:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82360caa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File mountain_100.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mrc(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont\u001b[39m\u001b[38;5;124m'\u001b[39m,family\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMalgun Gothic\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mrc(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m,unicode_minus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 21\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmountain_100.json\u001b[39m\u001b[38;5;124m'\u001b[39m,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     23\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlot\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m경도\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrtrlId\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m아이디\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctpvNm\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m시도명\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrtrDt\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m데이터추출일시\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maslAltide\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m해발고도\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmtnCd\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m산코드\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddrNm\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m주소\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrtrlNm\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m산명\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m위도\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     24\u001b[0m                        })\n",
      "File \u001b[1;32mD:\\kdt\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:760\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    758\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 760\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m JsonReader(\n\u001b[0;32m    761\u001b[0m     path_or_buf,\n\u001b[0;32m    762\u001b[0m     orient\u001b[38;5;241m=\u001b[39morient,\n\u001b[0;32m    763\u001b[0m     typ\u001b[38;5;241m=\u001b[39mtyp,\n\u001b[0;32m    764\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    765\u001b[0m     convert_axes\u001b[38;5;241m=\u001b[39mconvert_axes,\n\u001b[0;32m    766\u001b[0m     convert_dates\u001b[38;5;241m=\u001b[39mconvert_dates,\n\u001b[0;32m    767\u001b[0m     keep_default_dates\u001b[38;5;241m=\u001b[39mkeep_default_dates,\n\u001b[0;32m    768\u001b[0m     precise_float\u001b[38;5;241m=\u001b[39mprecise_float,\n\u001b[0;32m    769\u001b[0m     date_unit\u001b[38;5;241m=\u001b[39mdate_unit,\n\u001b[0;32m    770\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    771\u001b[0m     lines\u001b[38;5;241m=\u001b[39mlines,\n\u001b[0;32m    772\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    773\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    774\u001b[0m     nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[0;32m    775\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    776\u001b[0m     encoding_errors\u001b[38;5;241m=\u001b[39mencoding_errors,\n\u001b[0;32m    777\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    778\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    779\u001b[0m )\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[1;32mD:\\kdt\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:861\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 861\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_from_filepath(filepath_or_buffer)\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[1;32mD:\\kdt\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:917\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    909\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    912\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    916\u001b[0m ):\n\u001b[1;32m--> 917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filepath_or_buffer\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File mountain_100.json does not exist"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font',family='Malgun Gothic') \n",
    "plt.rc('axes',unicode_minus=False)\n",
    "\n",
    "df = pd.read_json('mountain_100.json',encoding='UTF-8')\n",
    "df = pd.json_normalize(df['response']['body']['items']['item'])\n",
    "df = df.rename(columns={'lot': '경도', 'frtrlId': '아이디','ctpvNm':'시도명','crtrDt':'데이터추출일시','aslAltide':'해발고도','mtnCd':'산코드','addrNm':'주소','frtrlNm':'산명','lat':'위도'\n",
    "                       })\n",
    "\n",
    "# 웹드라이버 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "# 버전에 상관 없이 os에 설치된 크롬 브라우저 사용\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(3)\n",
    "# 버전에 상관 없이 os에 설치된 크롬 브라우저 사용\n",
    "\n",
    "\n",
    "# Naver API key 입력\n",
    "client_id = \"ShIovNz7SXGAFNygBoVx\"\n",
    "client_secret = \"1Gh1DzPsn3\"\n",
    "\n",
    "\n",
    "# selenium으로 검색 페이지 불러오기 #\n",
    "naver_urls = []\n",
    "postdate = []\n",
    "titles = []\n",
    "\n",
    "\n",
    "\n",
    "# 검색을 끝낼 페이지 입력\n",
    "menu = input('100대 명산 채크 [명산]/ 일반 검색 [Enter]')\n",
    "\n",
    "if(menu=='명산'):\n",
    "    # 검색어 입력\n",
    "    keword = input(\"검색할 키워드를 입력해주세요:\")\n",
    "    encText = urllib.parse.quote(keword)\n",
    "    farst = input(\"\\n크롤링을 시작 위치를 입력해주세요. (기본값:1, 최대값:100):\")  \n",
    "    if farst == \"\":\n",
    "        farst = 1\n",
    "    else:\n",
    "        end = int(end)\n",
    "    end = input(\"\\n반복될 카운팅을 입력해주세요. (기본값:1, 최대값:100):\")  \n",
    "    if end == \"\":\n",
    "        end = 1\n",
    "    else:\n",
    "        end = int(end)\n",
    "    print(farst,\" ~\",int(farst) + end, \"페이지 까지 크롤링을 진행 합니다\")\n",
    "else:\n",
    "    keword = input(\"검색할 키워드를 입력해주세요:\")\n",
    "    encText = urllib.parse.quote(keword)\n",
    "    farst = input(\"\\n크롤링을 시작 위치를 입력해주세요. (기본값:1, 최대값:100):\")  \n",
    "    if farst == \"\":\n",
    "        farst = 1\n",
    "    else:\n",
    "        end = int(end)\n",
    "    end = input(\"\\n마지막 위치 입력해주세요. (기본값:1, 최대값:100):\")  \n",
    "    if end == \"\":\n",
    "        end = 1\n",
    "    else:\n",
    "        end = int(end)\n",
    "    print(farst,\" ~\",int(farst) + end, \"페이지 까지 크롤링을 진행 합니다\")\n",
    "\n",
    "    \n",
    "# 한번에 가져올 페이지 입력\n",
    "display = input(\"\\n한번에 가져올 페이지 개수를 입력해주세요.(기본값:10, 최대값: 100):\")\n",
    "if display == \"\":\n",
    "    display = 10\n",
    "else:\n",
    "    display = int(display)\n",
    "print(\"\\n한번에 가져올 페이지 : \", display, \"페이지\")\n",
    "name = keword\n",
    "\n",
    "for start in range(end):\n",
    "    print(start+1+int(farst))\n",
    "    url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText + \"&start=\" + str(start+1+int(farst)) + \"&display=\" + str(display+1) # JSON 결과\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    print(start+1+int(farst))\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        \n",
    "        data = json.loads(response_body.decode('utf-8'))['items']\n",
    "        for row in data:\n",
    "            if('blog.naver' in row['link']):\n",
    "                naver_urls.append(row['link'])\n",
    "                postdate.append(row['postdate'])\n",
    "                title = row['title']\n",
    "                # html태그제거\n",
    "                pattern1 = '<[^>]*>'\n",
    "                title = re.sub(pattern=pattern1, repl='', string=title)\n",
    "                titles.append(title)\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "    farst = int(farst)  \n",
    "    display = int(display)\n",
    "    farst += display\n",
    "\n",
    "###naver 기사 본문 및 제목 가져오기###\n",
    "\n",
    "# ConnectionError방지\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/98.0.4758.102\"}\n",
    "\n",
    "\n",
    "contents = []\n",
    "comments_texts = []\n",
    "try:\n",
    "    for i in naver_urls:\n",
    "        print(i)\n",
    "        driver.get(i)\n",
    "        time.sleep(5)  # 대기시간 변경 가능\n",
    "\n",
    "        iframe = driver.find_element(By.ID , \"mainFrame\") # id가 mainFrame이라는 요소를 찾아내고 -> iframe임\n",
    "        driver.switch_to.frame(iframe) # 이 iframe이 내가 찾고자하는 html을 포함하고 있는 내용\n",
    "\n",
    "        source = driver.page_source\n",
    "        html = BeautifulSoup(source, \"html.parser\")\n",
    "        # 검색결과 확인용\n",
    "        # with open(\"Output.txt\", \"w\") as text_file:\n",
    "        #     text_file.write(str(html))\n",
    "        \n",
    "        # 기사 텍스트만 가져오기\n",
    "        content = html.select(\"div.se-main-container\")\n",
    "        #  list합치기\n",
    "        content = ''.join(str(content))\n",
    "\n",
    "        # html태그제거 및 텍스트 다듬기\n",
    "        content = re.sub(pattern=pattern1, repl='', string=content)\n",
    "        pattern2 = \"\"\"[\\n\\n\\n\\n\\n// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\"\"\"\n",
    "        content = content.replace(pattern2, '')\n",
    "        content = content.replace('\\n', '')\n",
    "        content = content.replace('\\u200b', '')\n",
    "        contents.append(content)\n",
    "\n",
    "    name = namedata+'blog.csv'\n",
    "    news_df = pd.DataFrame({'title': titles, 'content': contents, 'date': postdate})\n",
    "    news_df.to_csv(name, index=False, encoding='utf-8-sig')\n",
    "except:\n",
    "    contents.append('error')\n",
    "    news_df = pd.DataFrame({'title': titles, 'content': contents, 'date': postdate})\n",
    "    news_df.to_csv('blog.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a17e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfde8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
